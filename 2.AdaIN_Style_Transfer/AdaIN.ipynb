{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": " AdaIN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbDtAmy1Sfjx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import Image as display_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZhm5PPMSrZi"
      },
      "source": [
        "def calc_mean_std(feat, eps=1e-5):\n",
        "    size = feat.size()\n",
        "    assert (len(size) == 4)\n",
        "    N, C = size[:2]\n",
        "    feat_var = feat.view(N, C, -1).var(dim=2) + eps\n",
        "    feat_std = feat_var.sqrt().view(N, C, 1, 1)\n",
        "    feat_mean = feat.view(N, C, -1).mean(dim=2).view(N, C, 1, 1)\n",
        "    return feat_mean, feat_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJOiMHbTSrlp"
      },
      "source": [
        "def adaptive_instance_normalization(content_feat, style_feat):\n",
        "    assert (content_feat.size()[:2] == style_feat.size()[:2])\n",
        "    size = content_feat.size()\n",
        "    style_mean, style_std = calc_mean_std(style_feat)\n",
        "    content_mean, content_std = calc_mean_std(content_feat)\n",
        "\n",
        "\n",
        "    normalized_feat = (content_feat - content_mean.expand(size)) / content_std.expand(size)\n",
        "\n",
        "    return normalized_feat * style_std.expand(size) + style_mean.expand(size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCK2VeZeSrpE"
      },
      "source": [
        "\n",
        "vgg = nn.Sequential(\n",
        "    nn.Conv2d(3, 3, (1, 1)),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(3, 64, (3, 3)),\n",
        "    nn.ReLU(), # relu1-1\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(64, 64, (3, 3)),\n",
        "    nn.ReLU(), # relu1-2\n",
        "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(64, 128, (3, 3)),\n",
        "    nn.ReLU(), # relu2-1\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(128, 128, (3, 3)),\n",
        "    nn.ReLU(), # relu2-2\n",
        "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(128, 256, (3, 3)),\n",
        "    nn.ReLU(), # relu3-1\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(), # relu3-2\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(), # relu3-3\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(), # relu3-4\n",
        "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 512, (3, 3)),\n",
        "    nn.ReLU(), # relu4-1, this is the last layer used\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(), # relu4-2\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(), # relu4-3\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(), # relu4-4\n",
        "    nn.MaxPool2d((2, 2), (2, 2), (0, 0), ceil_mode=True),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(), # relu5-1\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(), # relu5-2\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU(), # relu5-3\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 512, (3, 3)),\n",
        "    nn.ReLU() # relu5-4\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6skIx4rSrwF"
      },
      "source": [
        "decoder = nn.Sequential(\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(512, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 256, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(256, 128, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(128, 128, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(128, 64, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(64, 64, (3, 3)),\n",
        "    nn.ReLU(),\n",
        "    nn.ReflectionPad2d((1, 1, 1, 1)),\n",
        "    nn.Conv2d(64, 3, (3, 3)),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bodJnMJFSrzm",
        "outputId": "60a7388b-90fd-471b-f7e0-e0f95c4e67bb"
      },
      "source": [
        "!wget https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/Ebs6XES37otLgWW5cavCY9YByGOnXJD5wC0WZgQPp8vAJg?download=1 -O decoder.pth\n",
        "!wget https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EXzxBZI0seBFuxucQjlShBEBtM7X5-Lmj-ceqZ5Fu96alA?download=1 -O vgg_normalised.pth"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-21 07:30:27--  https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/Ebs6XES37otLgWW5cavCY9YByGOnXJD5wC0WZgQPp8vAJg?download=1\n",
            "Resolving postechackr-my.sharepoint.com (postechackr-my.sharepoint.com)... 13.107.136.9, 13.107.138.9\n",
            "Connecting to postechackr-my.sharepoint.com (postechackr-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/dongbinna_postech_ac_kr/Documents/Research/models/AdaIN%20Style%20Transfer/decoder.pth [following]\n",
            "--2021-11-21 07:30:29--  https://postechackr-my.sharepoint.com/personal/dongbinna_postech_ac_kr/Documents/Research/models/AdaIN%20Style%20Transfer/decoder.pth\n",
            "Reusing existing connection to postechackr-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14023458 (13M) [application/octet-stream]\n",
            "Saving to: ‘decoder.pth’\n",
            "\n",
            "decoder.pth         100%[===================>]  13.37M  4.94MB/s    in 2.7s    \n",
            "\n",
            "2021-11-21 07:30:32 (4.94 MB/s) - ‘decoder.pth’ saved [14023458/14023458]\n",
            "\n",
            "--2021-11-21 07:30:32--  https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EXzxBZI0seBFuxucQjlShBEBtM7X5-Lmj-ceqZ5Fu96alA?download=1\n",
            "Resolving postechackr-my.sharepoint.com (postechackr-my.sharepoint.com)... 13.107.136.9, 13.107.138.9\n",
            "Connecting to postechackr-my.sharepoint.com (postechackr-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/dongbinna_postech_ac_kr/Documents/Research/models/AdaIN%20Style%20Transfer/vgg_normalised.pth [following]\n",
            "--2021-11-21 07:30:33--  https://postechackr-my.sharepoint.com/personal/dongbinna_postech_ac_kr/Documents/Research/models/AdaIN%20Style%20Transfer/vgg_normalised.pth\n",
            "Reusing existing connection to postechackr-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 80102481 (76M) [application/octet-stream]\n",
            "Saving to: ‘vgg_normalised.pth’\n",
            "\n",
            "vgg_normalised.pth  100%[===================>]  76.39M  21.4MB/s    in 4.2s    \n",
            "\n",
            "2021-11-21 07:30:38 (18.0 MB/s) - ‘vgg_normalised.pth’ saved [80102481/80102481]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ3bmBI8Sr3L"
      },
      "source": [
        "decoder.eval()\n",
        "vgg.eval()\n",
        "\n",
        "vgg_path = './vgg_normalised.pth'\n",
        "decoder_path = './decoder.pth'\n",
        "\n",
        "decoder.load_state_dict(torch.load(decoder_path))\n",
        "vgg.load_state_dict(torch.load(vgg_path))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vgg.to(device)\n",
        "decoder.to(device)\n",
        "\n",
        "vgg = nn.Sequential(*list(vgg.children())[:31])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m9BBU6TTPys"
      },
      "source": [
        "def style_transfer(vgg, decoder, content, style, alpha=1.0):\n",
        "    assert (0.0 <= alpha <= 1.0)\n",
        "    content_f = vgg(content)\n",
        "    style_f = vgg(style)\n",
        "    feat = adaptive_instance_normalization(content_f, style_f)\n",
        "    feat = feat * alpha + content_f * (1 - alpha)\n",
        "    return decoder(feat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4sYygEJTP2B"
      },
      "source": [
        "def test_transform(size=512):\n",
        "    transform_list = []\n",
        "    if size != 0:\n",
        "        transform_list.append(transforms.Resize(size))\n",
        "    transform_list.append(transforms.ToTensor())\n",
        "    transform = transforms.Compose(transform_list)\n",
        "    return transform\n",
        "\n",
        "content_tf = test_transform()\n",
        "style_tf = test_transform()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgCOL-ovXwJn",
        "outputId": "fcc52663-3ac1-4d80-85e0-ade227368243"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "A4_TWzhkeH9l",
        "outputId": "860e3eb8-6d82-45f9-95a2-ce0416d60119"
      },
      "source": [
        "content_path = '/content/drive/MyDrive/Colab Notebooks/AdaIN/content/content1.jpg'\n",
        "style_path = '/content/drive/MyDrive/Colab Notebooks/AdaIN/style/style1.jpg'\n",
        "\n",
        "content = content_tf(Image.open(str(content_path)))\n",
        "style = style_tf(Image.open(str(style_path)))\n",
        "\n",
        "style = style.to(device).unsqueeze(0)\n",
        "content = content.to(device).unsqueeze(0)\n",
        "with torch.no_grad():\n",
        "    output = style_transfer(vgg, decoder, content, style, alpha=1.0)\n",
        "output = output.cpu()\n",
        "\n",
        "save_image(output, 'output1.png')\n",
        "\n",
        "from torchvision.utils import save_image\n",
        "save_image(output.cpu().detach()[0], 'output1.png')\n",
        "print('이미지 파일 저장을 완료했습니다.')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('output1.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이미지 파일 저장을 완료했습니다.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6a8b77c1-69db-4dda-9f1b-ed6dbb991b1a\", \"output12.png\", 937574)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}